{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 20000 images belonging to 2 classes.\n",
      "[Compiling Started]\n",
      "[Compiling Complete]\n",
      "[Training Started]\n",
      "INFO:tensorflow:Initializing RunConfig with distribution strategies.\n",
      "INFO:tensorflow:Not using Distribute Coordinator.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmprq3znonr\n",
      "INFO:tensorflow:Using the Keras model provided.\n",
      "INFO:tensorflow:Using config: {'_log_step_count_steps': 100, '_session_creation_timeout_secs': 7200, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_task_type': 'worker', '_task_id': 0, '_num_worker_replicas': 1, '_experimental_distribute': None, '_tf_random_seed': None, '_num_ps_replicas': 0, '_keep_checkpoint_max': 5, '_global_id_in_cluster': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7ff0c06a4978>, '_save_summary_steps': 100, '_master': '', '_model_dir': '/tmp/tmprq3znonr', '_evaluation_master': '', '_eval_distribute': None, '_experimental_max_worker_delay_secs': None, '_train_distribute': <tensorflow.python.distribute.mirrored_strategy.MirroredStrategy object at 0x7ff0c06a4a58>, '_service': None, '_device_fn': None, '_keep_checkpoint_every_n_hours': 10000, '_distribute_coordinator_mode': None, '_save_checkpoints_steps': None, '_is_chief': True, '_protocol': None}\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "from_generator() missing 1 required positional argument: 'output_types'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-c048b12eee5e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    217\u001b[0m \u001b[0;31m#     print('%s (%.2f%%)' % (label[1], label[2] * 100))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 219\u001b[0;31m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    220\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-c048b12eee5e>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    166\u001b[0m \u001b[0;31m#     shapes = ([None], ())\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m \u001b[0;31m#     types = (tf.string, tf.int32)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 168\u001b[0;31m     \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainGen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    169\u001b[0m \u001b[0;31m#     estimator.train(trainData,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m \u001b[0;31m#                         steps_per_epoch=num_train_samples // batch_size,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: from_generator() missing 1 required positional argument: 'output_types'"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.keras.preprocessing.image import img_to_array\n",
    "from tensorflow.python.keras.applications.vgg16 import preprocess_input\n",
    "from tensorflow.python.keras.applications.vgg16 import decode_predictions\n",
    "from tensorflow.python.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.python.keras.preprocessing.image import load_img\n",
    "from tensorflow.python.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.python.keras.utils import multi_gpu_model\n",
    "#from keras.preprocessing import image\n",
    "from tensorflow.python.keras.models import Sequential\n",
    "from tensorflow.python.keras.layers import Conv2D, MaxPooling2D, ZeroPadding2D\n",
    "from tensorflow.python.keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from tensorflow.python.keras import backend as K\n",
    "import numpy as np\n",
    "\n",
    "trainingDir =\"data/train/\"\n",
    "validationDir = \"data/validation/\"\n",
    "\n",
    "# Training Model\n",
    "# VGG Stats According to Paper\n",
    "# Batch Size = 256\n",
    "# Epoch = 74\n",
    "# Dense = 24.8/7.5\n",
    "# Multi Crop = 24.6/7.5\n",
    "num_train_samples = 5000\n",
    "num_val_samples = 500\n",
    "epochs = 74\n",
    "batch_size = 256\n",
    "\n",
    "def loadDataSet():\n",
    "    img_width, img_height = 224, 224\n",
    "\n",
    "    if K.image_data_format() == \"channels_first\":\n",
    "        input_shape = (3, img_width, img_height)\n",
    "    else:\n",
    "        input_shape = (img_width, img_height, 3)\n",
    "\n",
    "    trainData = ImageDataGenerator(\n",
    "        rescale = 1. /225,\n",
    "        shear_range = 0.2,\n",
    "        zoom_range = 0.2,\n",
    "        horizontal_flip = True)\n",
    "\n",
    "    testData = ImageDataGenerator(rescale=1./225)\n",
    "\n",
    "    trainGen = trainData.flow_from_directory(\n",
    "        trainingDir,\n",
    "        target_size = (img_width, img_height),\n",
    "        batch_size = batch_size,\n",
    "        class_mode = \"categorical\")\n",
    "\n",
    "#     validationGen = testData.flow_from_directory(\n",
    "#         validationDir,\n",
    "#         target_size = (img_width, img_height),\n",
    "#         batch_size = batch_size,\n",
    "#         class_mode = \"categorical\")\n",
    "    \n",
    "#     xTrain, yTrain = trainGen.next()\n",
    "#     xVal, yVal = validationGen.next()\n",
    "\n",
    "    return trainGen \n",
    "    #return trainGen, validationGen\n",
    "\n",
    "def VGG_16():\n",
    "#     strategy = tf.distribute.MirroredStrategy(devices=[\"/gpu:0\", \"/gpu:1\"])\n",
    "#     with strategy.scope():\n",
    "    model = Sequential()\n",
    "    model.add(ZeroPadding2D((1, 1), input_shape=(224, 224, 3)))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "    \n",
    "    model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "    \n",
    "    model.add(Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "\n",
    "    model.add(Conv2D(512, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(Conv2D(512, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(Conv2D(512, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "\n",
    "    model.add(Conv2D(512, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(Conv2D(512, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(Conv2D(512, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    \n",
    "    # top layer of the VGG net\n",
    "    model.add(Dense(4096, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(4096, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    \n",
    "    model.add(Dense(2, activation='softmax', name=\"posts\"))\n",
    "        \n",
    "#     print(\"[Compiling Started]\")\n",
    "#     model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "#     print(\"[Compiling Complete]\")\n",
    "    \n",
    "#     model.summary()\n",
    "# #     try:\n",
    "# #         model = multi_gpu_model(model)\n",
    "# #     except:\n",
    "# #         print(\"Failure\")\n",
    "# #         pass\n",
    "    \n",
    "#     #model.load_weights(\"VGGTrainedWeights\")\n",
    "#     xTrain, yTrain, xVal, yVal, trainGen, validationGen = loadDataSet()\n",
    "#     print(\"TGEN: \", trainGen)\n",
    "#     print(\"VGEN: \", validationGen)\n",
    "#     print(\"XTRAIN: \", xTrain)\n",
    "#     print(\"YTRAIN: \", yTrain)\n",
    "#     print(\"XVAL: \", xVal)\n",
    "#     print(\"YVAL: \", yVal)\n",
    "#     spe = num_train_samples // batch_size\n",
    "#     vs = num_val_samples // batch_size\n",
    "#     yTrain = keras.utils.to_categorical(yTrain, 3)\n",
    "#     yVal = keras.utils.to_categorical(yVal, 3)\n",
    "#     model.fit(xTrain, yTrain,\n",
    "#               steps_per_epoch=spe,\n",
    "#               epochs=epochs,\n",
    "#               validation_data=(xVal,yVal),\n",
    "#               validation_steps=vs)\n",
    "#     model.save_weights(\"VGGTrainedWeightsV2\")\n",
    "#     print(\"ITSATASGARWGWEGHIEWGAPIWEGSNSAIDPFNDPISFHWAEIPFHAWIESFNAIEWPFGHW\")\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "def main(): # load the model\n",
    "    model = VGG_16()\n",
    "    trainGen = loadDataSet()\n",
    "    #xTrain, yTrain, xVal, yVal = loadDataSet()\n",
    "    #model.compile(optimizer='sgd', loss='categorical_crossentropy')\n",
    "    \n",
    "    \n",
    "    print(\"[Compiling Started]\")\n",
    "    model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"], name='labels')\n",
    "    print(\"[Compiling Complete]\")\n",
    "    print(\"[Training Started]\")\n",
    "    \n",
    "    NUM_GPUS = 8\n",
    "    strategy = tf.distribute.MirroredStrategy()\n",
    "    config = tf.estimator.RunConfig(train_distribute=strategy)\n",
    "    estimator = tf.keras.estimator.model_to_estimator(model,\n",
    "                                                  config=config)\n",
    "#     estimator = tf.keras.estimator.model_to_estimator(keras_model=model,\n",
    "#                                                       keras_model_path=None,\n",
    "#                                                       custom_objects=None,\n",
    "#                                                       model_dir=None,\n",
    "#                                                       config=config,\n",
    "#                                                       checkpoint_format='checkpoint')\n",
    "\n",
    "    spe = num_train_samples // batch_size\n",
    "    vs = num_val_samples // batch_size\n",
    "#     print(\"DATATYPE: \", type(tuple(xTrain)))\n",
    "#     shapes = ([None], ())\n",
    "#     types = (tf.string, tf.int32)\n",
    "    dataset = tf.data.Dataset.from_generator(trainGen)\n",
    "#     estimator.train(trainData,\n",
    "#                         steps_per_epoch=num_train_samples // batch_size,\n",
    "#                         epochs=epochs,\n",
    "#                         validation_data=valData,\n",
    "#                         validation_steps=num_val_samples // batch_size)\n",
    "    estimator.train(dataset)\n",
    "                    #hooks=None,\n",
    "                    #steps=None,\n",
    "                    \n",
    "                    #saving_listeners=None)\n",
    "#     model.fit_generator(trainData,\n",
    "#               steps_per_epoch=spe,\n",
    "#               epochs=epochs,\n",
    "#               validation_data=valData,\n",
    "#               validation_steps=vs)\n",
    "#     estimator.save_weights(\"VGGTrainedWeightsV2\")\n",
    "    print(\"[Training Complete]\")\n",
    "\n",
    "    # load an image from file\n",
    "    image = load_img('data/test/male/000030.jpg', target_size=(224, 224))\n",
    "    # convert the image pixels to a numpy array\n",
    "    image = img_to_array(image)\n",
    "\n",
    "    #image_pred = np.expand_dims(image_pred, axis = 0)\n",
    "    image = image.reshape((1, image.shape[0], image.shape[1], image.shape[2]))\n",
    "    image = preprocess_input(image)\n",
    "    rslt = model.predict(image)\n",
    "    # print(\"Laberl: \", label)\n",
    "    #list(filter(lambda num: num != 0, rslt[0]))\n",
    "    print(rslt)\n",
    "    # if(rslt[0][0] > rslt[0][1]):\n",
    "    #     prediction = \"Male\"\n",
    "    # else:\n",
    "    #     prediction = \"Female\"\n",
    "    # print(prediction)\n",
    "\n",
    "    # # reshape data for the model\n",
    "    # image = image.reshape((1, image.shape[0], image.shape[1], image.shape[2]))\n",
    "    # # prepare the image for the VGG model\n",
    "    # image = preprocess_input(image)\n",
    "    # # predict the probability across all output classes\n",
    "    # yhat = model.predict(image)\n",
    "    # # convert the probabilities to class labels\n",
    "#     label = decode_predictions(rslt)\n",
    "#     print(label)\n",
    "#     # # retrieve the most likely result, e.g. highest probability\n",
    "#     label = label[0][0]\n",
    "#     # # print the classification\n",
    "#     print('%s (%.2f%%)' % (label[1], label[2] * 100))\n",
    "\n",
    "main()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
